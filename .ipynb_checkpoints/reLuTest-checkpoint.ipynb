{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416b3715-b239-4ce1-8841-4d75fbc8bfc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LeakyReLu' from 'tensorflow.keras.layers' (/home/jules/project/pro/lib/python3.10/site-packages/keras/api/_v2/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential \u001b[38;5;66;03m#regroupement de layer formant le modele\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#dense == tensor ou layer ou ensemble de neurons d'un mm niveau \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, BatchNormalization, LeakyReLu \u001b[38;5;66;03m#layer instance\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#import la fct elu pour pouvoir gerer HP alpha\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m relu\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LeakyReLu' from 'tensorflow.keras.layers' (/home/jules/project/pro/lib/python3.10/site-packages/keras/api/_v2/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential #regroupement de layer formant le modele\n",
    "#dense == tensor ou layer ou ensemble de neurons d'un mm niveau \n",
    " \n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU #layer instance\n",
    "\n",
    "#import la fct elu pour pouvoir gerer HP alpha\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "###HYPERPARAM###\n",
    "# type d'archi qu'on veut \n",
    "architecture = [5,39, 40, 31, 42, 1]#small\n",
    "#big = \"[61,51,28,39,26,2120,14,1]\"\n",
    "\n",
    "dropoutRate = 0.2\n",
    "learningRate = 0.001\n",
    "testPercent = 0.2\n",
    "maxEpochs = 850 #pas trop important car peut de chance d'overfitt\n",
    "\n",
    "alphaActi = 0.2 #! >=0  = pente pour tt x en dessous de thresold\n",
    "clipGrad = 1\n",
    "\n",
    "\n",
    "\n",
    "# met la LUT\n",
    "data = pd.read_csv('./src/sort.csv') \n",
    "\n",
    "data = shuffle(data)\n",
    "\n",
    "\n",
    "features = data.iloc[:, 1:6].values #inputs\n",
    "targets = data.iloc[:, 7].values #target outputs\n",
    "\n",
    "# normalisation std\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "##import to save bc use it when want to predict\n",
    "mean_value = scaler.mean_\n",
    "std_deviation = scaler.scale_\n",
    "\n",
    "#new_data = scaler.transform(new_data) to the input for prediction\n",
    "\n",
    "\n",
    "#create the model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# Add the layers\n",
    "\n",
    "for layer, neurons in enumerate(architecture):\n",
    "    model.add(\n",
    "        Dense(\n",
    "            neurons, \n",
    "            activation=LeakyReLu(alpha=alphaActi),#relu(alpha=alphaActi, threshold=thresholdActi), \n",
    "            input_shape=(neurons,)\n",
    "            )\n",
    "        )\n",
    "    if layer == 1 or layer == 2:\n",
    "        model.add(Dropout(dropoutRate))\n",
    "    if layer != 0 and layer != len(architecture) - 1:\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "# tt les 32 epochs lr perd 4%\n",
    "#schedule == function to give to LearningScheduler, with epoch and lr as param\n",
    "def lr_scheduler(epoch, lr):          #to modify and/or add to HP   \n",
    "    if epoch % 32 == 0 and epoch > 0:\n",
    "        return lr * 0.96\n",
    "    return lr\n",
    "\n",
    "print(maxEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659eed5-7fa3-4df4-906d-65146e681188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
