{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41433546-c14c-4bde-af02-c4ce669a09a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown dtype: <class 'type'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 33\u001b[0m\n\u001b[1;32m     25\u001b[0m HP_BATCHNORM \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mHParam(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_normalisation\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     26\u001b[0m                          hp\u001b[38;5;241m.\u001b[39mDiscrete([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]))\n\u001b[1;32m     29\u001b[0m HP_SEED \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mHParam(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     30\u001b[0m                     hp\u001b[38;5;241m.\u001b[39mDiscrete([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     32\u001b[0m HP_OPTIMIZER \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mHParam(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m---> 33\u001b[0m                          \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msgd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnrmse\u001b[39m(y_true, y_pred):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K\u001b[38;5;241m.\u001b[39msqrt(K\u001b[38;5;241m.\u001b[39mmean(K\u001b[38;5;241m.\u001b[39msquare(y_pred \u001b[38;5;241m-\u001b[39m y_true)))\u001b[38;5;241m/\u001b[39mK\u001b[38;5;241m.\u001b[39mmean(y_true)\n",
      "File \u001b[0;32m~/project/pro/lib/python3.10/site-packages/tensorboard/plugins/hparams/summary_v2.py:507\u001b[0m, in \u001b[0;36mDiscrete.__init__\u001b[0;34m(self, values, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty domain with no dtype specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown dtype: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (dtype,))\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values:\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown dtype: <class 'type'>"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import ast\n",
    "#trouver un moyen de rapidment eleminer certaines valeurs\n",
    "# Define the hyperparameters\n",
    "#utilise pas tout mais definis un range et lesquels sont possible\n",
    "\n",
    "#cles du dict hparams\n",
    "HP_ARCHITECTURE = hp.HParam('architecture',\n",
    "                              hp.Discrete(['[5, 39, 40, 31, 42, 1]',\n",
    "                                           '[5, 61, 51, 28, 39, 26, 21,20, 14, 1]']))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', \n",
    "                             hp.Discrete([i/1000 for i in range(1,10,1)]))\n",
    "HP_DROPOUT_RATE = hp.HParam('drouptout_rate',\n",
    "                            hp.Discrete([i/10 for i in range(1,10,1)]))\n",
    "HP_LRDECAY_RATE = hp.HParam('lrDecay_rate', \n",
    "                            hp.Discrete([i/100 for i in range(60,100,10)]))\n",
    "HP_RYTHM_RATE = hp.HParam('rythm', \n",
    "                          hp.Discrete([i for i in range(10,30,10)]))\n",
    "HP_ALPHA_ACTI = hp.HParam('alpha_acti', \n",
    "                          hp.Discrete([i/50 for i in range(0,10,1)]))\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', \n",
    "                          hp.Discrete([16,32,64]))\n",
    "HP_BATCHNORM = hp.HParam('batch_normalisation', \n",
    "                         hp.Discrete([True, False]))\n",
    "\n",
    "\n",
    "HP_SEED = hp.HParam('seed', \n",
    "                    hp.Discrete([0,1,2]))\n",
    "\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', \n",
    "                         hp.Discrete(['adam','sgd']))\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))/K.mean(y_true)\n",
    "    \n",
    "myMetrics = [hp.Metric('msle', display_name='msle'), \n",
    "             hp.Metric('mape', display_name='mape')]#,\n",
    "             #hp.Metric(nrmse, display_name='nrmse')]\n",
    "\n",
    "\n",
    "\n",
    "# Configure the hyperparameters and metrics for TensorBoard\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[\n",
    "            HP_ARCHITECTURE, \n",
    "            HP_LEARNING_RATE,\n",
    "            HP_DROPOUT_RATE,\n",
    "            HP_LRDECAY_RATE,\n",
    "            HP_RYTHM_RATE,\n",
    "            HP_ALPHA_ACTI,\n",
    "            HP_BATCH_SIZE,\n",
    "            HP_BATCHNORM,\n",
    "            HP_SEED,\n",
    "            HP_OPTIMIZER\n",
    "            ],\n",
    "        metrics=myMetrics,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(x_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(x_test, y_test)\n",
    "  return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "      \n",
    "model.fit(\n",
    "    ...,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "        hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f44432",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,x\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcc284-964c-44fd-9413-877390e07cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ou alors\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Define your hyperparameters\n",
    "learning_rate = 0.001\n",
    "units = 64\n",
    "\n",
    "# Create a summary writer and start a new session\n",
    "writer = tf.summary.create_file_writer('logs/hparams')\n",
    "\n",
    "# Define the hyperparameter configuration\n",
    "hyperparams = {\n",
    "    'learning_rate': learning_rate,\n",
    "    'units': units\n",
    "}\n",
    "\n",
    "# Log the hyperparameters\n",
    "with writer.as_default():\n",
    "    hp.hparams(hyperparams)  # Log the hyperparameters\n",
    "\n",
    "\"\"\"\n",
    "# Start the TensorBoard server to visualize the logs\n",
    "# Open a terminal or command prompt and navigate to the directory containing your code\n",
    "# Run the fol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72802194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
